{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset, Dataloader, BatchNorm, Dropout, Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJY4fA2YZtc4k8rMM8/CXD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteAndBlackFox/LearningPyTorch/blob/DDBDO/Dataset%2C_Dataloader%2C_BatchNorm%2C_Dropout%2C_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset, Dataloader, BatchNorm, Dropout, Оптимизация"
      ],
      "metadata": {
        "id": "668YzKjNLAeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Используя датасет недвижимости (sklearn.datasets.fetch_california_housing)\n",
        "Необходимо:\n",
        "* Создать Dataset для загрузки данных\n",
        "* Обернуть его в Dataloader\n",
        "* Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
        "* Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели\n",
        "\n",
        "При этом train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25."
      ],
      "metadata": {
        "id": "Xl_xyRZOLQIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подключаем необходимые библиотеки"
      ],
      "metadata": {
        "id": "iXVRXPcQRVsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam, RMSprop, SGD\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "SPdbPCmsLDAY"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Глобальные переменные"
      ],
      "metadata": {
        "id": "TStGNjYHcbjb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "dgyEqrhgJmZs"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "EPOCHES = 10\n",
        "LR = 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создадим Dataset"
      ],
      "metadata": {
        "id": "_fowHSgezEOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CHDataset(Dataset):\n",
        "  def __init__(self, *init_datasets):\n",
        "    assert all(init_datasets[0].size(0) == init_dataset.size(0) for init_dataset in init_datasets), \"Несоотвутствует размерность среди dataset\"\n",
        "    self._base_datasets = init_datasets\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self._base_datasets[0].size(0)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "      return tuple(base_dataset[idx] for base_dataset in self._base_datasets)"
      ],
      "metadata": {
        "id": "GmUM9VbFjcJS"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Опишем нейронную сеть"
      ],
      "metadata": {
        "id": "6xxppgS-znZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CHNet(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "      super(CHNet, self).__init__()\n",
        "      self.block_1 = nn.Sequential(\n",
        "          nn.Linear(in_features=8, out_features=100, bias=True),\n",
        "          nn.Dropout(0.1),\n",
        "          nn.BatchNorm1d(100),\n",
        "          nn.ReLU())\n",
        "      self.block_2 = nn.Sequential(\n",
        "          nn.Linear(in_features=100, out_features=100, bias=True),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.BatchNorm1d(100),\n",
        "          nn.ReLU())\n",
        "      self.block_3 = nn.Sequential(\n",
        "          nn.Linear(in_features=100, out_features=60, bias=True),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.BatchNorm1d(60),\n",
        "          nn.ReLU())\n",
        "      self.block_4 = nn.Sequential(\n",
        "          nn.Linear(in_features=60, out_features=30),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.BatchNorm1d(30),\n",
        "          nn.ReLU())\n",
        "      self.predict = nn.Sequential(\n",
        "          nn.Linear(in_features=30, out_features=1, bias=True),\n",
        "          nn.BatchNorm1d(1),\n",
        "          nn.ReLU())\n",
        "  \n",
        "  def forward(self, inp):\n",
        "    out = self.block_1(inp)\n",
        "    out = self.block_2(out)\n",
        "    out = self.block_3(out)\n",
        "    out = self.block_4(out)\n",
        "    out = self.predict(out)\n",
        "    return out[:, 0]"
      ],
      "metadata": {
        "id": "tgH8tfLntAyw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функция для оценки оптимизации"
      ],
      "metadata": {
        "id": "DyzTAmHhzuVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(train_loader, test_loader, net, optimizer):\n",
        "  loss_fn = nn.MSELoss()\n",
        "  best_acc = {'train': None, 'test': None}\n",
        "  net.train()\n",
        "  for epoch in range(EPOCHES):\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        \n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 150 == 0 or (i + 1) == len(train_loader):    # печатаем каждые 150 mini-batches\n",
        "            net.eval()\n",
        "\n",
        "            test_loss, test_running_total, test_loss  = 0.0, 0.0, 0.0\n",
        "            for y, (out_test, lbl_test) in enumerate(test_loader):\n",
        "                test_outputs = net(out_test)\n",
        "                test_loss += loss_fn(test_outputs, lbl_test)\n",
        "                test_running_total += len(lbl_test)\n",
        "            \n",
        "            res_loss_train = running_loss / running_items\n",
        "            res_loss_test = test_loss / test_running_total\n",
        "            \n",
        "            if best_acc['train'] is None or res_loss_train < best_acc['train']:\n",
        "              best_acc['train'] = res_loss_train\n",
        "            \n",
        "            if best_acc['test'] is None or res_loss_test < best_acc['test']:\n",
        "              best_acc['test'] = res_loss_train\n",
        "\n",
        "            print(f'Epoch [{epoch + 1}/{EPOCHES}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {res_loss_train:.3f}. '\\\n",
        "                  f'Test acc: {res_loss_test:.3f}.')\n",
        "            \n",
        "            running_loss, running_items = 0.0, 0.0\n",
        "            net.train()\n",
        "  print(f\"Best acc train: {best_acc['train']:.3f}. Best acc test: {best_acc['test']:.3f}\")\n",
        "  print('Training is finished!')"
      ],
      "metadata": {
        "id": "3qufHpd73AS2"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Начало анализа"
      ],
      "metadata": {
        "id": "O34h0mrl02tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "california_housing = fetch_california_housing()\n",
        "# Разделим на тестовые и тренеровочные данные\n",
        "X_train, X_test, y_train, y_test = train_test_split(california_housing.data, california_housing.target, test_size=0.25, random_state=13)"
      ],
      "metadata": {
        "id": "wJLuPNoMo_rB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализуем данные и подготовим их для дальнейшего использования в нашем dstaset\n",
        "scale = StandardScaler()\n",
        "X_train_s = scale.fit_transform(X_train)\n",
        "X_test_s = scale.transform(X_test)"
      ],
      "metadata": {
        "id": "Y7iJiuQ8sZ1J"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_xt = torch.from_numpy(X_train_s.astype(np.float32)).to(DEVICE)\n",
        "train_yt = torch.from_numpy(y_train.astype(np.float32)).to(DEVICE)\n",
        "\n",
        "test_xt = torch.from_numpy(X_test_s.astype(np.float32)).to(DEVICE)\n",
        "test_yt = torch.from_numpy(y_test.astype(np.float32)).to(DEVICE)"
      ],
      "metadata": {
        "id": "kmA0J6Tt94rl"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CHDataset(train_xt, train_yt)\n",
        "test_dataset = CHDataset(test_xt, test_yt)"
      ],
      "metadata": {
        "id": "FnufbmuTbDfk"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=2, drop_last=True)"
      ],
      "metadata": {
        "id": "ZvzYqOA4rdEZ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Дальшей начнем анализ по таким оптимизаторам как Adam, RMSProp, SGD и SGD + Momentum"
      ],
      "metadata": {
        "id": "4mPYYgXp1q9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam"
      ],
      "metadata": {
        "id": "uONCFvQo6OOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet().to(DEVICE)\n",
        "optimizer = Adam(net.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "Pg9JDK4u26IX"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm8v-0Eu5Wv-",
        "outputId": "66b28146-c6ca-49c6-c7d8-2f92646451b5"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/241]. Loss: 0.074. Test acc: 0.077.\n",
            "Epoch [1/10]. Step [151/241]. Loss: 0.025. Test acc: 0.009.\n",
            "Epoch [1/10]. Step [241/241]. Loss: 0.010. Test acc: 0.009.\n",
            "Epoch [2/10]. Step [1/241]. Loss: 0.007. Test acc: 0.009.\n",
            "Epoch [2/10]. Step [151/241]. Loss: 0.008. Test acc: 0.010.\n",
            "Epoch [2/10]. Step [241/241]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [3/10]. Step [1/241]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [3/10]. Step [151/241]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [3/10]. Step [241/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [4/10]. Step [1/241]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [4/10]. Step [151/241]. Loss: 0.007. Test acc: 0.010.\n",
            "Epoch [4/10]. Step [241/241]. Loss: 0.007. Test acc: 0.010.\n",
            "Epoch [5/10]. Step [1/241]. Loss: 0.005. Test acc: 0.010.\n",
            "Epoch [5/10]. Step [151/241]. Loss: 0.007. Test acc: 0.011.\n",
            "Epoch [5/10]. Step [241/241]. Loss: 0.007. Test acc: 0.014.\n",
            "Epoch [6/10]. Step [1/241]. Loss: 0.007. Test acc: 0.014.\n",
            "Epoch [6/10]. Step [151/241]. Loss: 0.007. Test acc: 0.012.\n",
            "Epoch [6/10]. Step [241/241]. Loss: 0.007. Test acc: 0.012.\n",
            "Epoch [7/10]. Step [1/241]. Loss: 0.004. Test acc: 0.012.\n",
            "Epoch [7/10]. Step [151/241]. Loss: 0.007. Test acc: 0.011.\n",
            "Epoch [7/10]. Step [241/241]. Loss: 0.006. Test acc: 0.012.\n",
            "Epoch [8/10]. Step [1/241]. Loss: 0.006. Test acc: 0.012.\n",
            "Epoch [8/10]. Step [151/241]. Loss: 0.006. Test acc: 0.011.\n",
            "Epoch [8/10]. Step [241/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [9/10]. Step [1/241]. Loss: 0.007. Test acc: 0.009.\n",
            "Epoch [9/10]. Step [151/241]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [9/10]. Step [241/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [1/241]. Loss: 0.012. Test acc: 0.013.\n",
            "Epoch [10/10]. Step [151/241]. Loss: 0.006. Test acc: 0.010.\n",
            "Epoch [10/10]. Step [241/241]. Loss: 0.006. Test acc: 0.008.\n",
            "Best acc train: 0.004. Best acc test: 0.006\n",
            "Training is finished!\n",
            "CPU times: user 19.1 s, sys: 3.45 s, total: 22.6 s\n",
            "Wall time: 28.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RMSProp"
      ],
      "metadata": {
        "id": "Sgc7oehAPX6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet().to(DEVICE)\n",
        "optimizer = RMSprop(net.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "RiEFVkYoPWZj"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWyfURT1PdhZ",
        "outputId": "0b47a11c-a3e5-4ad9-921f-1805741bda91"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/241]. Loss: 0.078. Test acc: 0.088.\n",
            "Epoch [1/10]. Step [151/241]. Loss: 0.015. Test acc: 0.008.\n",
            "Epoch [1/10]. Step [241/241]. Loss: 0.009. Test acc: 0.010.\n",
            "Epoch [2/10]. Step [1/241]. Loss: 0.009. Test acc: 0.010.\n",
            "Epoch [2/10]. Step [151/241]. Loss: 0.008. Test acc: 0.010.\n",
            "Epoch [2/10]. Step [241/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [3/10]. Step [1/241]. Loss: 0.011. Test acc: 0.006.\n",
            "Epoch [3/10]. Step [151/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [3/10]. Step [241/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [4/10]. Step [1/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [4/10]. Step [151/241]. Loss: 0.007. Test acc: 0.008.\n",
            "Epoch [4/10]. Step [241/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [1/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [151/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [5/10]. Step [241/241]. Loss: 0.007. Test acc: 0.011.\n",
            "Epoch [6/10]. Step [1/241]. Loss: 0.006. Test acc: 0.011.\n",
            "Epoch [6/10]. Step [151/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [6/10]. Step [241/241]. Loss: 0.007. Test acc: 0.008.\n",
            "Epoch [7/10]. Step [1/241]. Loss: 0.004. Test acc: 0.008.\n",
            "Epoch [7/10]. Step [151/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [241/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [1/241]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [151/241]. Loss: 0.006. Test acc: 0.012.\n",
            "Epoch [8/10]. Step [241/241]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [1/241]. Loss: 0.003. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [151/241]. Loss: 0.006. Test acc: 0.010.\n",
            "Epoch [9/10]. Step [241/241]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [10/10]. Step [1/241]. Loss: 0.005. Test acc: 0.007.\n",
            "Epoch [10/10]. Step [151/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [10/10]. Step [241/241]. Loss: 0.006. Test acc: 0.007.\n",
            "Best acc train: 0.003. Best acc test: 0.003\n",
            "Training is finished!\n",
            "CPU times: user 17.1 s, sys: 3.23 s, total: 20.3 s\n",
            "Wall time: 25.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD"
      ],
      "metadata": {
        "id": "Ykjrw7qRQ3R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet().to(DEVICE)\n",
        "optimizer = SGD(net.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "rCbhKfC3Q2Rr"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN5hPG5OQ61a",
        "outputId": "24787429-539c-4597-f3b7-c698c28c0c9c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/241]. Loss: 0.050. Test acc: 0.088.\n",
            "Epoch [1/10]. Step [151/241]. Loss: 0.025. Test acc: 0.011.\n",
            "Epoch [1/10]. Step [241/241]. Loss: 0.011. Test acc: 0.011.\n",
            "Epoch [2/10]. Step [1/241]. Loss: 0.010. Test acc: 0.010.\n",
            "Epoch [2/10]. Step [151/241]. Loss: 0.010. Test acc: 0.010.\n",
            "Epoch [2/10]. Step [241/241]. Loss: 0.010. Test acc: 0.009.\n",
            "Epoch [3/10]. Step [1/241]. Loss: 0.009. Test acc: 0.008.\n",
            "Epoch [3/10]. Step [151/241]. Loss: 0.009. Test acc: 0.008.\n",
            "Epoch [3/10]. Step [241/241]. Loss: 0.008. Test acc: 0.009.\n",
            "Epoch [4/10]. Step [1/241]. Loss: 0.010. Test acc: 0.009.\n",
            "Epoch [4/10]. Step [151/241]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [4/10]. Step [241/241]. Loss: 0.008. Test acc: 0.008.\n",
            "Epoch [5/10]. Step [1/241]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [151/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [241/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [6/10]. Step [1/241]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [6/10]. Step [151/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [6/10]. Step [241/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [7/10]. Step [1/241]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [7/10]. Step [151/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [241/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [8/10]. Step [1/241]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [8/10]. Step [151/241]. Loss: 0.007. Test acc: 0.009.\n",
            "Epoch [8/10]. Step [241/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [1/241]. Loss: 0.004. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [151/241]. Loss: 0.007. Test acc: 0.008.\n",
            "Epoch [9/10]. Step [241/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [1/241]. Loss: 0.003. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [151/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [10/10]. Step [241/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Best acc train: 0.003. Best acc test: 0.004\n",
            "Training is finished!\n",
            "CPU times: user 16.3 s, sys: 3.41 s, total: 19.7 s\n",
            "Wall time: 25.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD + Momentum"
      ],
      "metadata": {
        "id": "Nt9P7h3-RFKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet().to(DEVICE)\n",
        "optimizer = SGD(net.parameters(), lr=LR, momentum=0.8)"
      ],
      "metadata": {
        "id": "4w_Hf1HlRJB7"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saKPdEKiRNVK",
        "outputId": "de5714eb-c551-4746-cc8e-ee3105849066"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/241]. Loss: 0.064. Test acc: 0.087.\n",
            "Epoch [1/10]. Step [151/241]. Loss: 0.015. Test acc: 0.008.\n",
            "Epoch [1/10]. Step [241/241]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [2/10]. Step [1/241]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [2/10]. Step [151/241]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [2/10]. Step [241/241]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [3/10]. Step [1/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [3/10]. Step [151/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [3/10]. Step [241/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [4/10]. Step [1/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [4/10]. Step [151/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [4/10]. Step [241/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [5/10]. Step [1/241]. Loss: 0.009. Test acc: 0.006.\n",
            "Epoch [5/10]. Step [151/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [5/10]. Step [241/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [6/10]. Step [1/241]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [6/10]. Step [151/241]. Loss: 0.007. Test acc: 0.009.\n",
            "Epoch [6/10]. Step [241/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [1/241]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [151/241]. Loss: 0.007. Test acc: 0.010.\n",
            "Epoch [7/10]. Step [241/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [1/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [151/241]. Loss: 0.006. Test acc: 0.008.\n",
            "Epoch [8/10]. Step [241/241]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [1/241]. Loss: 0.004. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [151/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [9/10]. Step [241/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [1/241]. Loss: 0.004. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [151/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [10/10]. Step [241/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Best acc train: 0.004. Best acc test: 0.005\n",
            "Training is finished!\n",
            "CPU times: user 16.6 s, sys: 3.27 s, total: 19.9 s\n",
            "Wall time: 25.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вывод\n",
        "\n",
        "Поставим ограничение (выбирались рандомно): \n",
        "* Количество эпох - EPOCHES=10\n",
        "* Размер батча в DataLoader - batch_size=64\n",
        "* Скорость обучения - lr=0.01\n",
        "\n",
        "*Вариация сетки* **первая**:\n",
        "\n",
        "*Linear* > *BatchNorm1d* > *ReLU* > *Dropout*\n",
        "\n",
        "*Сводка полученных данных*:\n",
        "* Adam: \n",
        "  * скорость работы 27.8 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.004\n",
        "    * тестовый вариант 0.005\n",
        "* RMSprop:\n",
        "  * скорость работы 25.5 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.004\n",
        "    * тестовый вариант 0.006\n",
        "* SGD:\n",
        "  * скорость работы 24.7 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.005\n",
        "    * тестовый вариант 0.006\n",
        "* SGD + Momentum:\n",
        "  * скорость работы 26.3 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.005\n",
        "    * тестовый вариант 0.005\n",
        "\n",
        "**Результат**: Наибыстрый вариант функции сходимости оказался: SGD, по скорости отстала функция Adam. Наилучшие точности (оценивается по тестовым данным) стали методы: SGD + Momentum и Adam. Получается, что более точная модель требует больше времени.\n",
        "\n",
        "***Комментарий***: Попробовать изменить вариацию сетки.\n",
        "\n",
        "*Вариация сетки* **вторая**:\n",
        "\n",
        "*Linear* > *ReLU* > *BatchNorm1d* > *Dropout*\n",
        "\n",
        "*Сводка полученных данных*:\n",
        "* Adam: \n",
        "  * скорость работы 26.3 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.004\n",
        "    * тестовый вариант 0.005\n",
        "* RMSprop:\n",
        "  * скорость работы 24.8 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.003\n",
        "    * тестовый вариант 0.003\n",
        "* SGD:\n",
        "  * скорость работы 24.2 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.004\n",
        "    * тестовый вариант 0.004\n",
        "* SGD + Momentum:\n",
        "  * скорость работы 24.7 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.004\n",
        "    * тестовый вариант 0.006\n",
        "\n",
        "**Результат**: Наибыстрый вариант функции сходимости оказался: SGD, по скорости отстала функция Adam. Наилучшая точность (оценивается по тестовым данным) стали методы: RMSProp. По сравнению с первой вариацией нейронной сети, в данной получилось ускорить работу по всем функциям сходимости и в некоторых получилось улучшить точность.\n",
        "\n",
        "***Комментарий***: Если брать только по функции RMSProp, то выглядит оптимально... Стоит ли менять? Можно попробовать поменять вариацию.\n",
        "\n",
        "*Вариация сетки* **третья**:\n",
        "\n",
        "*Linear* > *Dropout* > *BatchNorm1d* > *ReLU*\n",
        "\n",
        "*Сводка полученных данных*:\n",
        "* Adam: \n",
        "  * скорость работы 28.1 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.004\n",
        "    * тестовый вариант 0.006\n",
        "* RMSprop:\n",
        "  * скорость работы 25.5 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.003\n",
        "    * тестовый вариант 0.003\n",
        "* SGD:\n",
        "  * скорость работы 25.7 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.003\n",
        "    * тестовый вариант 0.004\n",
        "* SGD + Momentum:\n",
        "  * скорость работы 25.2 s\n",
        "  * наилучшая точность:\n",
        "    * тренеровочный вариант 0.004\n",
        "    * тестовый вариант 0.005\n",
        "\n",
        "**Результат**: Наибыстрый вариант функции сходимости оказался: SGD+Momentum, по скорости отстала функция Adam. Наилучшая точность (оценивается по тестовым данным) стали методы: RMSProp. По сравнению с предыдущими эта сетка самая плохая на данный момент, т.к. время увеличилось, точнасть не сильно изменилась.\n",
        "\n",
        "***Комментарий***: Хм... Нет... Просто нет :D Такую сетку использовать не вижу смысла, только для тестирования если только :D\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y-T0L_vO132p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FW8RgbAb30tg"
      },
      "execution_count": 76,
      "outputs": []
    }
  ]
}