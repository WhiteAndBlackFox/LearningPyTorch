{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteAndBlackFox/LearningPyTorch/blob/GAN/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB8SF2_Zn6Tb"
      },
      "source": [
        "# Generative Adversarial Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtR_m45Kn5jS"
      },
      "source": [
        "Обучить генератор создавать точки, которые будут лежать на графике функции\n",
        "\n",
        "**y = sin(x)/x - x/10**\n",
        "\n",
        "При выполнении необходимо:\n",
        "- Сгенерировать настоящие данные\n",
        "- Изменить архитектуру дискриминатора и генератора\n",
        "- Построить графики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r1Y8sQrgn1aN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.animation as animation\n",
        "from IPython import display\n",
        "from torchvision.utils import save_image, make_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "linv5zB4raPE",
        "outputId": "c474e6d1-62a8-4015-f981-8187d447f85c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sqORV6PkZ4jq"
      },
      "outputs": [],
      "source": [
        "# Функция для вывода и сохранения изображения\n",
        "def sample_image(static_sample, save_img = False):\n",
        "    npimg = make_grid(static_sample.data[:25]).cpu().numpy()\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "    ax.imshow(np.transpose(npimg, (1,2,0)), interpolation=\"nearest\")\n",
        "    if save_img:\n",
        "        save_image(gen_imgs.data[:25], f\"images/{batches_done}.png\", nrow=5, normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hS_Pu7sbreYz"
      },
      "outputs": [],
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "n_epochs = 20  # количество эпох\n",
        "lr = 0.0002  # шаг обучения\n",
        "\n",
        "b1 = 0.5  # гиперпараметр для оптимайзера Adam\n",
        "b2 = 0.999  # гиперпараметр для оптимайзера Adam\n",
        "\n",
        "latent_dim = 100  # Размерность случайного вектора, который подается на вход генератору\n",
        "\n",
        "sample_interval = 500  # количество итераций для отображения процесса обучения\n",
        "\n",
        "img_size = 128  # размер картинки, которую мы будет подавать в нейронные сети\n",
        "channels = 1  # количество каналов в нашей картинке\n",
        "batch_size = 16  # размер батча\n",
        "img_shape = (channels, img_size, img_size)  # полный шейп нашей картинки\n",
        "\n",
        "real_data = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"./data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.Resize(img_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5], [0.5])\n",
        "        ]),\n",
        "    ),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP6-ZzM9tBit",
        "outputId": "955148ad-0efe-4879-9944-17a0a76a523d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "environ({'CUDNN_VERSION': '8.0.5.39', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'CLOUDSDK_PYTHON': 'python3', 'LANG': 'en_US.UTF-8', 'HOSTNAME': 'ce641f66d0b8', 'OLDPWD': '/', 'CLOUDSDK_CONFIG': '/content/.config', 'NVIDIA_VISIBLE_DEVICES': 'all', 'DATALAB_SETTINGS_OVERRIDES': '{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\\\"172.28.0.2\\\\\"\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\",\"enableLsp\":true}', 'ENV': '/root/.bashrc', 'NCCL_VERSION': '2.7.8', 'TF_FORCE_GPU_ALLOW_GROWTH': 'true', 'NO_GCE_CHECK': 'False', 'PWD': '/', 'HOME': '/root', 'LAST_FORCED_REBUILD': '20220407', 'DEBIAN_FRONTEND': 'noninteractive', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'GCE_METADATA_TIMEOUT': '3', 'GLIBCPP_FORCE_NEW': '1', 'TBE_CREDS_ADDR': '172.28.0.1:8008', 'SHELL': '/bin/bash', 'GCS_READ_CACHE_BLOCK_SIZE_MB': '16', 'PYTHONWARNINGS': 'ignore:::pip._internal.cli.base_command', 'CUDA_VERSION': '11.1.1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'SHLVL': '0', 'PYTHONPATH': '/env/python', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 brand=tesla,driver>=450,driver<451', 'TBE_EPHEM_CREDS_ADDR': '172.28.0.1:8009', 'COLAB_GPU': '0', 'GLIBCXX_FORCE_NEW': '1', 'PATH': '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin', 'LD_PRELOAD': '/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4', 'JPY_PARENT_PID': '49', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'ENABLE_DIRECTORYPREFETCHER': '1', 'USE_AUTH_EPHEM': '1', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'CUDA_LAUNCH_BLOCKING': '1'})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "os.environ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kK2CZMIEum-z"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Linear(in_feat, out_feat)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(latent_dim, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(img_shape))),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        # sin(x)/x - x/10\n",
        "        img = self.model(z)\n",
        "        # img_1 = torch.div(torch.sin(img), img)\n",
        "        # img = torch.sub(img_1, torch.div(img, 10))\n",
        "        # img = torch.tanh(img)\n",
        "        return img.reshape(-1, *img_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WCzIb_8SuO3N"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(img_shape)), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img = img.reshape(img.size(0), -1)\n",
        "        return self.model(img)\n",
        "        # img_1 = torch.div(torch.sin(img), img)\n",
        "        # img = torch.eq(img_1, torch.div(img, 10))\n",
        "        # return img.reshape(-1, *img_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "De1pXZvTygCM"
      },
      "outputs": [],
      "source": [
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Для каждой нейронки свой опитимизатор\n",
        "optimizer_G = torch.optim.Adam(\n",
        "    generator.parameters(),\n",
        "    lr=lr, \n",
        "    betas=(b1, b2)\n",
        ")\n",
        "optimizer_D = torch.optim.Adam(\n",
        "    discriminator.parameters(), \n",
        "    lr=lr, \n",
        "    betas=(b1, b2)\n",
        ")\n",
        "\n",
        "# Но вот функция ошибки у нас будет одна общая\n",
        "adversarial_loss = torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "WIZMeYnJ-OIk",
        "outputId": "57a9616b-c289-483e-dcbc-0ff5df8fddc5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5ad3e2be7d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0md_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting Training Loop...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "d_loss_history = []\n",
        "g_loss_history = []\n",
        "fig = plt.figure()\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "for epoch in range(n_epochs):\n",
        "  for i, (imgs, labels) in enumerate(real_data):\n",
        "  ##################### Лейблы для данных: 1 - настоящие, 0 - сгенерированные ########\n",
        "      valid = torch.FloatTensor(batch_size, 1).fill_(1.0).to(device)\n",
        "      fake = torch.FloatTensor(batch_size, 1).fill_(0.0).to(device)\n",
        "\n",
        "      real_imgs = imgs.type(torch.FloatTensor).to(device)\n",
        "\n",
        "      # Генерация шума\n",
        "      z = torch.FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))).to(device)\n",
        "      \n",
        "      # Генерируем данные Генератором на основе шума\n",
        "      gen_imgs = generator(z)\n",
        "      # gen_imgs = torch.sub(torch.div(torch.sin(gen_imgs), gen_imgs), torch.div(gen_imgs, 10))\n",
        "      \n",
        "  ######################  Тренировка дискриминатора    ##########################\n",
        "      \n",
        "      # Получаем предсказания дискриминатора на основе реальных данных\n",
        "      real_pred = discriminator(real_imgs)\n",
        "      \n",
        "      # Тут сравниваем предсказанные значения Дискриминатора(на основе настоящих данных) с настоящими\n",
        "      d_real_loss = adversarial_loss(real_pred, valid)\n",
        "      \n",
        "      # Подаем сгенерированые данные на Дискриминатор \n",
        "      fake_pred = discriminator(gen_imgs)\n",
        "      \n",
        "      # расчитываем ошибку предсказанного с фейковыми лейблами\n",
        "      d_fake_loss = adversarial_loss(fake_pred, fake)\n",
        "      \n",
        "      # И усредняем два лосса в один\n",
        "      d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "      optimizer_D.zero_grad()\n",
        "      d_loss.backward()\n",
        "      optimizer_D.step()\n",
        "\n",
        "  ######################  Тренировка генератора    ##########################\n",
        "      \n",
        "      # генерация шума\n",
        "      z = torch.FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))).to(device)\n",
        "\n",
        "      # Генерируем данные Генератором на основе шума\n",
        "      gen_imgs = generator(z)\n",
        "      # gen_imgs = torch.sub(torch.div(torch.sin(gen_imgs), gen_imgs), torch.div(gen_imgs, 10))\n",
        "\n",
        "      # Подаем сгенерированые данные на Дискриминатор \n",
        "      fake_pred = discriminator(gen_imgs)\n",
        "\n",
        "      # Тут сравниваем предсказанные значения Дискриминатора (на основе сгенерировнных данных) с настоящими\n",
        "      g_loss = adversarial_loss(fake_pred, valid)\n",
        "      \n",
        "      # Делаем шаг обучения нашего Генератора\n",
        "      optimizer_G.zero_grad()\n",
        "      g_loss.backward()\n",
        "      optimizer_G.step()\n",
        "\n",
        "      \n",
        "  ######## Отображение процесса обучения и вывод функций потерь ############\n",
        "      batches_done = epoch * len(real_data) + i\n",
        "\n",
        "      if batches_done % sample_interval == 0 or i == len(real_data):\n",
        "          with torch.no_grad():\n",
        "              plt.clf()\n",
        "\n",
        "              display.clear_output(wait=False)\n",
        "              sample_image(gen_imgs)\n",
        "              print(f\"[Epoch {epoch}/{n_epochs}] [Batch {i}/{len(real_data)}]\", end='|')\n",
        "              print(f'[D loss: {d_loss.item()}] [G loss: {g_loss.item()}]') \n",
        "\n",
        "\n",
        "              # display.display(plt.gcf())\n",
        "              plt.show()\n",
        "              d_loss = d_loss.cpu().detach()\n",
        "              g_loss = g_loss.cpu().detach()\n",
        "\n",
        "\n",
        "              d_loss_history.append(d_loss)\n",
        "              g_loss_history.append(g_loss)\n",
        "\n",
        "              plt.plot(np.array(d_loss_history), label='D loss')\n",
        "              plt.plot(np.array(g_loss_history), label='G loss')\n",
        "              plt.legend()\n",
        "              plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOAvlz6/1pEvbzEpfX/+SIS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}